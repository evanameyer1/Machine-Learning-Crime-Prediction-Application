{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Dickey-Fuller Method to Verify Seasonality, Stationanarity, and Constancy of Our Datasets Before the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evanmeyer/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('../datasets/scoring/final_aggregation.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[(df.date <= pd.to_datetime('2016-12-31')) & (df.date >= pd.to_datetime('2016-01-01'))]\n",
    "train_df = df[(df.date <= pd.to_datetime('2019-01-01')) & (df.date > pd.to_datetime('2016-12-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/fdmfhfr55d5f2r62ltcl50vh0000gn/T/ipykernel_37344/1154098784.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.fillna(0, inplace=True)\n",
      "/var/folders/5d/fdmfhfr55d5f2r62ltcl50vh0000gn/T/ipykernel_37344/1154098784.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_df.fillna(0, inplace=True)\n",
    "train_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.set_index('date', inplace=True)\n",
    "train_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../datasets/training/SARIMA/test_df.csv', index=False)\n",
    "train_df.to_csv('../datasets/training/SARIMA/train_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dickey_fuller(df, col, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Check the stationarity of a column using the Dickey-Fuller test.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the time series data.\n",
    "    - col: Name of the column to test.\n",
    "    - significance_level: The significance level for hypothesis testing.\n",
    "\n",
    "    Returns:\n",
    "    - values: A dictionary containing ADF test results.\n",
    "    \"\"\"\n",
    "    chunk_df = df[[col]]\n",
    "    print(f'{datetime.now()}: Starting search for the ideal chunk size for column \"{col}\"...')\n",
    "\n",
    "    try:\n",
    "        adf_result = adfuller(chunk_df, autolag='AIC')\n",
    "        print(f'{datetime.now()}: Dickey-Fuller test was successful')\n",
    "        \n",
    "    except MemoryError:\n",
    "        print(f'{datetime.now()}: Memory limit exceeded for column \"{col}\".')\n",
    "        return None\n",
    "\n",
    "    # Store ADF test results for the column\n",
    "    values = {\n",
    "        'Column Name': col,\n",
    "        'Start Date': chunk_df.index[0],\n",
    "        'End Date': chunk_df.index[-1],\n",
    "        'ADF Statistic': adf_result[0],\n",
    "        'P-Value': adf_result[1],\n",
    "        'Significance Level': significance_level\n",
    "    }\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_arima(df, col, stationary_state, seasonal_period=24):\n",
    "    \"\"\"\n",
    "    Determine SARIMA model parameters using auto_arima.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the time series data.\n",
    "    - col: Name of the column to analyze.\n",
    "    - seasonal_period: Seasonal period for SARIMA model.\n",
    "\n",
    "    Returns:\n",
    "    - p, d, q, P, D, Q: Model parameters.\n",
    "    \"\"\"\n",
    "    if stationary_state:\n",
    "        stepwise_fit = pm.auto_arima(df[col], seasonal=True, m=seasonal_period,\n",
    "                                     suppress_warnings=True,\n",
    "                                     stepwise=True,\n",
    "                                     error_action=\"ignore\",\n",
    "                                     trace=True, n_fits=50)\n",
    "\n",
    "        print(f'{datetime.now()}: Seasonal Auto-ARIMA function was successful for column \"{col}\"')\n",
    "    else:\n",
    "        stepwise_fit = pm.auto_arima(df[col], seasonal=False,\n",
    "                                suppress_warnings=True,\n",
    "                                stepwise=True,\n",
    "                                error_action=\"ignore\",\n",
    "                                trace=True, n_fits=50)\n",
    "        print(f'{datetime.now()}: Non-Seasonal Auto-ARIMA function was successful for column \"{col}\": {str(e)}')\n",
    "\n",
    "    params = stepwise_fit.get_params()\n",
    "    p, d, q, P, D, Q = params.get('order', (0, 1, 1)), params.get('seasonal_order', (0, 1, 1, 24))\n",
    "\n",
    "    print(f'{datetime.now()}: Auto-ARIMA parameters successfully gathered for column \"{col}\"')\n",
    "\n",
    "    return p, d, q, P, D, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA_model(df, col, p, d, q, P, D, Q, stationary_state, m=24):\n",
    "    \"\"\"\n",
    "    Fit a SARIMA or ARIMA model based on the stationarity state.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the time series data.\n",
    "    - col: Name of the column to model.\n",
    "    - p, d, q: Parameters for the ARIMA component.\n",
    "    - P, D, Q: Parameters for the seasonal component (SARIMA).\n",
    "    - seasonal_state: True if data is stationary, False otherwise.\n",
    "    - m: Seasonal period for SARIMA model.\n",
    "\n",
    "    Returns:\n",
    "    - results: Fitted SARIMA or ARIMA model.\n",
    "    \"\"\"\n",
    "    if stationary_state:\n",
    "        print(f'{datetime.now()}: Data for column \"{col}\" is stationary. Fitting SARIMA model.')\n",
    "        model = SARIMAX(df[col],\n",
    "                        order=(p, d, q),\n",
    "                        seasonal_order=(P, D, Q, m))\n",
    "    else:\n",
    "        print(f'{datetime.now()}: Data for column \"{col}\" is not stationary. Fitting ARIMA model instead.')\n",
    "        model = ARIMA(df[col], order=(p, d, q))\n",
    "\n",
    "    results = model.fit()\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(df, col, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Process a specific column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the time series data.\n",
    "    - col: Name of the column to process.\n",
    "    - significance_level: The significance level for hypothesis testing.\n",
    "\n",
    "    Returns:\n",
    "    - results: Fitted SARIMA or ARIMA model for the column.\n",
    "    \"\"\"\n",
    "    values = dickey_fuller(df, col, significance_level)\n",
    "    if values is not None:\n",
    "        seasonality_state = (values['P-Value'] < values['Significance Level'])\n",
    "        p, d, q, P, D, Q = auto_arima(df[col], seasonality_state)\n",
    "        results = ARIMA_model(df[col], p, d, q, P, D, Q, seasonality_state)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df, exempt_col):\n",
    "    \"\"\"\n",
    "    Main function to process columns in the DataFrame using Dask.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the time series data.\n",
    "    - exempt_col: List of columns to exempt from processing.\n",
    "\n",
    "    Returns:\n",
    "    - final_results: List of fitted SARIMA or ARIMA models for selected columns.\n",
    "    \"\"\"\n",
    "    df_dask = dd.from_pandas(df, npartitions=8)  # Adjust the number of partitions as needed\n",
    "    final_results = df_dask.map_partitions(\n",
    "        lambda partition: [process_column(partition, col) for col in partition.columns if col not in exempt_col],\n",
    "        meta=pd.Series(dtype=object)\n",
    "    ).compute(scheduler=\"processes\")\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-24 01:28:18.343633: Initiating on \"non-violent\" column\n",
      "2023-10-24 01:28:18.344612: Starting search for the ideal chunk size for column \"non-violent\"...\n",
      "2023-10-24 01:32:17.615237: Dickey-Fuller test was successful\n",
      "Performing stepwise search to minimize aic\n"
     ]
    }
   ],
   "source": [
    "test_results = main(test_df, ['hour', 'area'])\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = main(train_df, ['hour', 'area'])\n",
    "train_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
