{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps(df):\n",
    "    all_dates = pd.date_range(start='2001-01-01', end='2023-10-10', freq='D')\n",
    "    all_hours = range(1, 24)\n",
    "    all_areas = range(1, 77)\n",
    "    date_hour_combinations = pd.DataFrame(([datetime.datetime.strptime(str(date)[0:10], \"%Y-%m-%d\"), hour, area] for date in all_dates for hour in all_hours for area in all_areas), columns=['date', 'hour', 'area'])\n",
    "    merged_df = date_hour_combinations.merge(df, on=['date', 'hour', 'area'], how='outer')\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data():\n",
    "    \n",
    "    #read in crime data to use as the base for aggregation\n",
    "    clean_crime = pd.read_csv('../clean_datasets/clean_crime.csv')\n",
    "\n",
    "    #clean the crime data so the aggregation process is smoother\n",
    "    clean_crime['date'] = [datetime.datetime.strptime(clean_crime.date.iloc[i], '%m/%d/%Y %I:%M:%S %p') for i in range(len(clean_crime))]\n",
    "    clean_crime['hour'] = clean_crime.date.apply(lambda x : (x.hour + 1))\n",
    "    clean_crime['date'] = clean_crime.date.apply(lambda x : x.date())\n",
    "\n",
    "    print('clean_crime successfully read in')\n",
    "\n",
    "    #group the crime dataset utilizing a count aggregation\n",
    "    grouped_crime = clean_crime.groupby(['date', 'hour', 'type', 'area']).size().reset_index(name='count')\n",
    "\n",
    "    #pivot the violent vs non-violent counts to display across our grouped columns\n",
    "    grouped_crime = grouped_crime.pivot_table(index=['date', 'hour', 'area'], columns='type', values='count', fill_value=0).reset_index()\n",
    "    grouped_crime.rename(columns={1 : \"non-violent\", 2 : 'violent'}, inplace=True)\n",
    "\n",
    "    print('crime dataset successfully grouped')\n",
    "\n",
    "    #call fill_gaps function\n",
    "    grouped_crime = fill_gaps(grouped_crime)\n",
    "\n",
    "    print('fill gaps function successfully ran in')\n",
    "\n",
    "    #read in the area reference data\n",
    "    area_reference = pd.read_csv('../scoring_datasets/area_reference.csv')\n",
    "    area_reference = [['id','cta_stations','police_stations','bus_stations','unemployment','per_capita_income',\n",
    "                       'no_hs_dip','gov_depend','crowded_housing','below_pov','bike_stations']]\n",
    "    \n",
    "    #merge the area_reference dataset on top of the grouped_crime data\n",
    "    grouped_crime.merge(area_reference, left_on='area', right_on='id', how='left')\n",
    "    grouped_crime.drop(columns=['id'], inplace=True)\n",
    "\n",
    "    #reorder the columns so they make more sense\n",
    "    desired_order = ['date', 'hour', 'area', 'cta_stations',\n",
    "                 'police_stations', 'bus_stations', 'bike_stations', 'unemployment',\n",
    "                 'per_capita_income', 'no_hs_dip', 'gov_depend', 'crowded_housing',\n",
    "                 'below_pov', 'non-violent', 'violent']\n",
    "    grouped_crime = grouped_crime[desired_order]\n",
    "\n",
    "    print('area reference data successfully merged')\n",
    "\n",
    "    #read in cta ridership dataset\n",
    "    clean_ridership = pd.read_csv('../clean_datasets/clean_ridership.csv')\n",
    "    clean_ridership = [['date','area','rides']]\n",
    "    \n",
    "    #match datatypes of columns and then merge the two datasets together\n",
    "    grouped_crime['date'] = pd.to_datetime(grouped_crime['date'])\n",
    "    grouped_crime = grouped_crime.merge(clean_ridership, on=['date', 'area'], how='left')\n",
    "    \n",
    "    print('clean ridership data successfully merged')\n",
    "\n",
    "    #read in divvy bike trips dataset\n",
    "    clean_divvy_trips = pd.read_csv('../clean_datasets/clean_divvy_trips.csv')\n",
    "    clean_divvy_trips = [['id','date','station_id','station_name','area']]\n",
    "\n",
    "    #match datatypes of columns and then group the dataset to make merging together easier\n",
    "    clean_divvy_trips['hour'] = pd.to_datetime(clean_divvy_trips['date']).dt.hour\n",
    "    clean_divvy_trips['date'] = pd.to_datetime(pd.to_datetime(clean_divvy_trips['date']).dt.date)\n",
    "    grouped_divvy = clean_divvy_trips.groupby(['date', 'hour', 'area'])['station_id'].agg('count').reset_index()  \n",
    "\n",
    "    #merge the grouped divvy data onto the base crime data  \n",
    "    grouped_crime = grouped_crime.merge(grouped_divvy, on=['date', 'hour', 'area'], how='left')\n",
    "    grouped_crime.rename(columns={'station_id' : 'bike_rides', 'rides' : 'train_rides'}, inplace=True)\n",
    "\n",
    "    print('clean divvy trips data successfully merged')\n",
    "\n",
    "    #read in the lighting data, group it for aggregation, and then merge it on top of the crime data\n",
    "    clean_lighting = pd.read_csv('../clean_datasets/clean_lighting.csv')\n",
    "    clean_lighting = [['date','id','lat','long','status','area']]\n",
    "\n",
    "    grouped_lighting = clean_lighting.groupby(['date', 'area'])['lat'].agg('count').reset_index()\n",
    "    grouped_lighting.date = pd.to_datetime(grouped_lighting.date)\n",
    "    grouped_crime = grouped_crime.merge(grouped_lighting, on=['date', 'area'], how='left')\n",
    "    grouped_crime.rename(columns={'lat' : 'lighting'}, inplace=True)\n",
    "\n",
    "    print('clean lighting data successfully merged')\n",
    "\n",
    "    #read in the vacant apartments data, group it for aggregation, and then merge it on top of the crime data\n",
    "    clean_vacant_buildings = pd.read_csv('../clean_datasets/clean_vacant_buildings.csv')\n",
    "    clean_vacant_buildings = [['date', 'id', 'lat', 'long', 'status', 'area']]\n",
    "\n",
    "    grouped_vacancies = clean_vacant_buildings.groupby(['date', 'area'])['long'].agg('count').reset_index()\n",
    "    grouped_vacancies.date = pd.to_datetime(grouped_vacancies.date)\n",
    "    grouped_crime = grouped_crime.merge(grouped_vacancies, on=['date', 'area'], how='left')\n",
    "    grouped_crime.rename(columns={'long' : 'lighting'}, inplace=True)\n",
    "\n",
    "    print('clean vacancies data successfully merged')\n",
    "\n",
    "    return grouped_crime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
