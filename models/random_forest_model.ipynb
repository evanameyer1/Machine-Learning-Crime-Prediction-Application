{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestModel:\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Initialize the RandomForestModel.\n",
    "\n",
    "        Parameters:\n",
    "        - data: The dataset for modeling.\n",
    "        - targets: The target variables to predict.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.model = None\n",
    "        self.wmape_output = None\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "        self.fit = None\n",
    "        self.wmape = None\n",
    "        self.pred_wmape = None\n",
    "        self.pred = None\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        Get all the instance variables in a dictionary format.\n",
    "\n",
    "        Returns:\n",
    "        - params_dict: A dictionary with instance variable names as keys and their values as values.\n",
    "        \"\"\"\n",
    "        params_dict = {\n",
    "            \"targets\": self.targets,\n",
    "            \"features\": self.features,\n",
    "            \"model\": self.model,\n",
    "            \"wmape_output\": self.wmape_output,\n",
    "            \"best_params\": self.best_params,\n",
    "            \"best_score\": self.best_score,\n",
    "            \"fit\": self.fit,\n",
    "            \"pred\": self.pred,\n",
    "            \"graph\": self.graph\n",
    "        }\n",
    "        return params_dict\n",
    "\n",
    "    def update_targets(self, targets):\n",
    "        \"\"\"\n",
    "        Update the target variables for modeling.\n",
    "\n",
    "        Parameters:\n",
    "        - targets: The new target variables to set.\n",
    "        \"\"\"\n",
    "        self.targets = targets\n",
    "\n",
    "    def update_data(self, data):\n",
    "        \"\"\"\n",
    "        Update the dataset for modeling.\n",
    "\n",
    "        Parameters:\n",
    "        - data: The new dataset to set.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def clean_data(self):\n",
    "        for df in [self.train_df, self.test_df]:\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df['hour'] = df['date'].dt.hour\n",
    "            df['day_of_week'] = df['date'].dt.dayofweek\n",
    "            df['day_of_year'] = df['date'].dt.dayofyear\n",
    "            df['month'] = df['date'].dt.month\n",
    "            df.drop('date', axis=1, inplace=True)\n",
    "        return self.train_df, self.test_df\n",
    "\n",
    "    def prepare_data(self,exempt=[]):\n",
    "        \"\"\"\n",
    "        Prepare the datasets for modeling.\n",
    "\n",
    "        Parameters:\n",
    "        - targets: The target variables to prepare the data for.\n",
    "\n",
    "        Returns:\n",
    "        - train_df, test_df: The prepared training and testing datasets.\n",
    "        \"\"\"\n",
    "        for target in self.targets:\n",
    "\n",
    "            for df in [self.train_df, self.test_df]:\n",
    "\n",
    "                # Shift by Date Cycles\n",
    "                df[f'{target[:2]}_next_hour'] = df[target].shift(-1)\n",
    "                df[f'{target[:2]}_next_day'] = df[target].rolling(window=24).sum()\n",
    "                df[f'{target[:2]}_next_weekday'] = df[target].rolling(window=7 * 24).sum()\n",
    "                df[f'{target[:2]}_next_month'] = df[target].rolling(window=30 * 24).sum()\n",
    "\n",
    "                # Lag by Date Cycles\n",
    "                df[f'{target[:2]}_inverse_hour'] = df[target].shift(1)\n",
    "                df[f'{target[:2]}_inverse_next_day'] = df[target].diff(24)\n",
    "                df[f'{target[:2]}_inverse_next_weekday'] = df[target].diff(7 * 24)\n",
    "                df[f'{target[:2]}_inverse_next_month'] = df[target].diff(30 * 24)\n",
    "\n",
    "                df.dropna(inplace=True)\n",
    "\n",
    "                # Rolling Mean by Date Cycles\n",
    "                df[f\"{target[:2]}_6hour_mean\"] = df[target].rolling(6).mean()\n",
    "                df[f\"{target[:2]}_12hour_mean\"] = df[target].rolling(12).mean()\n",
    "                df[f\"{target[:2]}_24hour_mean\"] = df[target].rolling(24).mean()\n",
    "                df[f\"{target[:2]}_week_mean\"] = df[target].rolling(24*7).mean()\n",
    "                df[f\"{target[:2]}_30day_mean\"] = df[target].rolling(24*30).mean()\n",
    "\n",
    "                # Rolling Min by Date Cycles\n",
    "                df[f\"{target[:2]}_6hour_min\"] = df[target].rolling(6).min()\n",
    "                df[f\"{target[:2]}_12hour_min\"] = df[target].rolling(12).min()\n",
    "                df[f\"{target[:2]}_24hour_min\"] = df[target].rolling(24).min()\n",
    "                df[f\"{target[:2]}_week_min\"] = df[target].rolling(24*7).min()\n",
    "                df[f\"{target[:2]}_30day_min\"] = df[target].rolling(24*30).min()\n",
    "\n",
    "                # Rolling Max by Date Cycles\n",
    "                df[f\"{target[:2]}_6hour_max\"] = df[target].rolling(6).max()\n",
    "                df[f\"{target[:2]}_12hour_max\"] = df[target].rolling(12).max()\n",
    "                df[f\"{target[:2]}_24hour_max\"] = df[target].rolling(24).max()\n",
    "                df[f\"{target[:2]}_week_max\"] = df[target].rolling(24*7).max()\n",
    "                df[f\"{target[:2]}_30day_max\"] = df[target].rolling(24*30).max()\n",
    "\n",
    "                # Rolling Standard Deviation by Date Cycles\n",
    "                df[f\"{target[:2]}_6hour_std\"] = df[target].rolling(6).std()\n",
    "                df[f\"{target[:2]}_12hour_std\"] = df[target].rolling(12).std()\n",
    "                df[f\"{target[:2]}_24hour_std\"] = df[target].rolling(24).std()\n",
    "                df[f\"{target[:2]}_week_std\"] = df[target].rolling(24*7).std()\n",
    "                df[f\"{target[:2]}_30day_std\"] = df[target].rolling(24*30).std()\n",
    "\n",
    "        self.features = [feature for feature in self.train_df.columns if feature not in self.targets or exempt]\n",
    "\n",
    "        return self.train_df, self.test_df, self.features\n",
    "    \n",
    "    def calculate_wae_rmse(self, reference, predictions):\n",
    "        \"\"\"\n",
    "        Calculate the Weighted Absolute Error (WAE), Root Mean Square Error (RMSE),\n",
    "        and their respective accuracies for a single target.\n",
    "\n",
    "        Parameters:\n",
    "        - reference: The reference dataset containing true values.\n",
    "        - predictions: The predicted values to compare to.\n",
    "\n",
    "        Returns:\n",
    "        - error_metrics: Dictionary containing WAE, RMSE, and their accuracies for the specified target.\n",
    "        \"\"\"\n",
    "        error_metrics = {}\n",
    "    \n",
    "        # Convert DataFrame or Series to NumPy arrays\n",
    "        y_true = reference.values\n",
    "        y_pred = predictions.values if isinstance(predictions, pd.Series) else predictions\n",
    "\n",
    "        # Calculate Weighted Absolute Error (WAE)\n",
    "        wae = np.sum(np.abs(y_true - y_pred))\n",
    "        error_metrics['wae'] = wae\n",
    "\n",
    "        # Calculate Root Mean Square Error (RMSE)\n",
    "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "        error_metrics['rmse'] = rmse\n",
    "\n",
    "        # Calculate the accuracy for WAE (WAE Accuracy)\n",
    "        wae_accuracy = 100 - (wae / np.sum(np.abs(y_true)) * 100)\n",
    "        error_metrics['wae_accuracy'] = wae_accuracy\n",
    "\n",
    "        # Calculate the accuracy for RMSE (RMSE Accuracy)\n",
    "        rmse_accuracy = 100 - (rmse / np.std(y_true) * 100)\n",
    "        error_metrics['rmse_accuracy'] = rmse_accuracy\n",
    "\n",
    "        self.error_metrics = error_metrics\n",
    "\n",
    "        return error_metrics\n",
    "\n",
    "    def tune_random_forest_hyperparameters(self, X, y):\n",
    "        \"\"\"\n",
    "        Tune the hyperparameters of a Random Forest model using GridSearchCV.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features.\n",
    "        - y: Target variable.\n",
    "\n",
    "        Returns:\n",
    "        - best_params: The best hyperparameters found by GridSearchCV.\n",
    "        - best_score: The best score achieved with the best hyperparameters.\n",
    "        \"\"\"\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "\n",
    "        rf = RandomForestRegressor(random_state=0, n_jobs=6)\n",
    "        grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        self.best_params = grid_search.best_params_\n",
    "        self.best_score = grid_search.best_score_\n",
    "\n",
    "        return self.best_params, self.best_score\n",
    "\n",
    "    def fit_model(self):\n",
    "        \"\"\"\n",
    "        Fit a RandomForestRegressor model to the training dataset.\n",
    "\n",
    "        Returns:\n",
    "        - output: A dictionary containing model-related information.\n",
    "        \"\"\"\n",
    "        train_df = self.train_df.copy()\n",
    "\n",
    "        imputer = SimpleImputer()\n",
    "        self.Xtr = imputer.fit_transform(train_df[self.features])\n",
    "        self.ytr = train_df[self.targets]\n",
    "\n",
    "        best_params, best_score = self.tune_random_forest_hyperparameters(self.Xtr, self.ytr)\n",
    "\n",
    "        mdl = RandomForestRegressor(n_estimators=best_params.get('n_estimators', 100),\n",
    "                                    max_depth=best_params.get('max_depth', None),\n",
    "                                    min_samples_split=best_params.get('min_samples_split', 2),\n",
    "                                    min_samples_leaf=best_params.get('min_samples_leaf', 1),\n",
    "                                    max_features=best_params.get('max_features', 'auto'),\n",
    "                                    random_state=best_params.get('random_state', 0),\n",
    "                                    n_jobs=best_params.get('n_jobs', 6))\n",
    "\n",
    "        mdl.fit(self.Xtr, self.ytr)\n",
    "\n",
    "        self.model = mdl\n",
    "        self.params = best_params\n",
    "        self.score = best_score\n",
    "\n",
    "        return self.parameters()\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict target values for the testing dataset and compare results.\n",
    "\n",
    "        Returns:\n",
    "        - pred: Predicted values for each target column.\n",
    "        \"\"\"\n",
    "        test_df = self.test_df.copy()\n",
    "\n",
    "        # Fit the imputer on your training data first\n",
    "        imputer = SimpleImputer()\n",
    "        imputer.fit(self.train_df[self.features])\n",
    "\n",
    "        # Transform the test data using the fitted imputer\n",
    "        Xtest = imputer.transform(test_df[self.features])\n",
    "\n",
    "        # Make predictions\n",
    "        pred = self.model.predict(Xtest)\n",
    "\n",
    "        self.pred = pred\n",
    "        return self.pred\n",
    "\n",
    "    def print_performance(self, target, sig_level=0.05):\n",
    "        important_features = [feature for feature in self.features if self.importance.get(feature, 0) > sig_level]\n",
    "        df = self.train_df.copy().dropna(subset=self.features).fillna(0)\n",
    "        important_df = df[important_features]\n",
    "        target_df = df[target]\n",
    "\n",
    "        # Train the random forest\n",
    "        rf_most_important = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "        rf_most_important.fit(important_df, target_df)\n",
    "\n",
    "        # Prepare the test data using the same important features\n",
    "        test_important_df = df[important_features].fillna(0)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = rf_most_important.predict(test_important_df)\n",
    "\n",
    "        print(predictions)\n",
    "\n",
    "        # Calculate WAE, RMSE, and their respective accuracies\n",
    "        error_metrics = self.calculate_wae_rmse(target_df, target)\n",
    "\n",
    "        # Display the performance metrics\n",
    "        print('Mean Absolute Error (WAE):', round(error_metrics['wae'], 4))\n",
    "        print('WAE Accuracy:', round(error_metrics['wae_accuracy'], 4), '%.')\n",
    "\n",
    "        print('Root Mean Square Error (RMSE):', round(error_metrics['rmse'], 4))\n",
    "        print('RMSE Accuracy:', round(error_metrics['rmse_accuracy'], 4), '%.')\n",
    "\n",
    "    def visualize_tree(self, tree_index, dot_loc, png_loc=None, new_params=None):\n",
    "        \"\"\"\n",
    "        Visualize a decision tree from the random forest model.\n",
    "\n",
    "        Args:\n",
    "            tree_index (int): Index of the tree to visualize.\n",
    "            dot_loc (str): File path to save the DOT file.\n",
    "            png_loc (str, optional): File path to save the visualization as a PNG file.\n",
    "\n",
    "        Returns:\n",
    "        - graph: A Pydot graph representing the decision tree.\n",
    "        \"\"\"\n",
    "        if new_params is not None:\n",
    "\n",
    "            tree_model = RandomForestRegressor(\n",
    "                n_estimators=new_params.get('n_estimators', self.params.get('n_estimators', 100)),\n",
    "                max_depth=new_params.get('max_depth', self.params.get('max_depth', None)),\n",
    "                min_samples_split=new_params.get('min_samples_split', self.params.get('min_samples_split', 2)),\n",
    "                min_samples_leaf=new_params.get('min_samples_leaf', self.params.get('min_samples_leaf', 1)),\n",
    "                max_features=new_params.get('max_features', self.params.get('max_features', 'auto')),\n",
    "                random_state=new_params.get('random_state', self.params.get('random_state', 0)),\n",
    "                n_jobs=new_params.get('n_jobs', self.params.get('n_jobs', 6))\n",
    "            )\n",
    "\n",
    "            tree_model.fit(self.Xtr, self.ytr)\n",
    "\n",
    "        else:\n",
    "            tree_model = self.model\n",
    "\n",
    "        if tree_index < 0 or tree_index >= len(tree_model.estimators_):\n",
    "            raise ValueError(f\"Invalid tree_index. It should be in the range [0, {len(tree_model.estimators_)-1}].\")\n",
    "        \n",
    "        tree = tree_model.estimators_[tree_index]\n",
    "        export_graphviz(\n",
    "            tree,\n",
    "            out_file=dot_loc,\n",
    "            feature_names=self.features,\n",
    "            rounded=True,\n",
    "            precision=1\n",
    "        )\n",
    "        (self.graph, ) = pydot.graph_from_dot_file(dot_loc)\n",
    "\n",
    "        if png_loc is not None:\n",
    "            self.graph.write_png(png_loc)\n",
    "\n",
    "        return self.graph\n",
    "\n",
    "    def print_importances(self, decimal_places=4):\n",
    "\n",
    "        importances = {}\n",
    "        \n",
    "        feature_importances = [(feature, round(importance, decimal_places)) for feature, importance in zip(self.features, self.model.feature_importances_)]\n",
    "        feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        for feature, importance in feature_importances:\n",
    "            importances[feature] = importance\n",
    "            print(f'Variable: {feature:20} Importance: {importance:.{decimal_places}f}')\n",
    "\n",
    "        self.importance = importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
