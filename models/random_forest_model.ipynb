{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "# Change date time to hour, day of week, day of year, month\n",
    "# Split data into NV and V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestModel:\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Initialize the RandomForestModel.\n",
    "\n",
    "        Parameters:\n",
    "        - data: The dataset for modeling.\n",
    "        - targets: The target variables to predict.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.model = None\n",
    "        self.wmape_output = None\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "        self.fit = None\n",
    "        self.wmape = None\n",
    "        self.pred_wmape = None\n",
    "        self.pred = None\n",
    "\n",
    "    def update_targets(self, targets):\n",
    "        \"\"\"\n",
    "        Update the target variables for modeling.\n",
    "\n",
    "        Parameters:\n",
    "        - targets: The new target variables to set.\n",
    "        \"\"\"\n",
    "        self.targets = targets\n",
    "\n",
    "    def update_data(self, data):\n",
    "        \"\"\"\n",
    "        Update the dataset for modeling.\n",
    "\n",
    "        Parameters:\n",
    "        - data: The new dataset to set.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_data():\n",
    "        \"\"\"\n",
    "        Clean the dataset (add your data cleaning logic here).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self, targets):\n",
    "        \"\"\"\n",
    "        Prepare the dataset for modeling.\n",
    "\n",
    "        Parameters:\n",
    "        - targets: The target variables to prepare the data for.\n",
    "\n",
    "        Returns:\n",
    "        - data: The prepared dataset.\n",
    "        \"\"\"\n",
    "        for target in targets:\n",
    "\n",
    "            # Shift by Date Cycles\n",
    "            self.data['next_hour'] = self.data[target].shift(-1)    \n",
    "            self.data['next_weekday'] = self.data.groupby('weekday')[target].agg('sum').shift(-1)\n",
    "            self.data['next_month'] = self.data.groupby('month')[target].agg('sum').shift(-1)\n",
    "        \n",
    "            # Lag by Date Cycles\n",
    "            self.data[\"lag_hour\"] = self.data[target].shift(1)\n",
    "            self.data[\"lag_weekday\"] = self.data.groupby('weekday')[target].agg('sum').shift(1)\n",
    "            self.data[\"lag_month\"] = self.data.groupby('month')[target].agg('sum').shift(1)\n",
    "\n",
    "            # Diff by Date Cycles\n",
    "            self.data[\"hour_diff\"] = self.data[target].diff(1)\n",
    "            self.data[\"weekday_diff\"] = self.data.groupby('weekday')[target].agg('sum').diff(1)\n",
    "            self.data[\"month_diff\"] = self.data.groupby('month')[target].agg('sum').diff(1)\n",
    "\n",
    "            self.data = self.data.dropna()\n",
    "\n",
    "            # Rolling Mean by Date Cycles\n",
    "            self.data[\"6hour_mean\"] = self.data[target].rolling(6).mean()\n",
    "            self.data[\"12hour_mean\"] = self.data[target].rolling(12).mean()\n",
    "            self.data[\"24hour_mean\"] = self.data[target].rolling(24).mean()\n",
    "            self.data[\"week_mean\"] = self.data[target].rolling(24*7).mean()\n",
    "            self.data[\"30day_mean\"] = self.data[target].rolling(24*30).mean()\n",
    "\n",
    "            # Rolling Min by Date Cycles\n",
    "            self.data[\"6hour_min\"] = self.data[target].rolling(6).min()\n",
    "            self.data[\"12hour_min\"] = self.data[target].rolling(12).min()\n",
    "            self.data[\"24hour_min\"] = self.data[target].rolling(24).min()\n",
    "            self.data[\"week_min\"] = self.data[target].rolling(24*7).min()\n",
    "            self.data[\"30day_min\"] = self.data[target].rolling(24*30).min()\n",
    "\n",
    "            # Rolling Max by Date Cycles\n",
    "            self.data[\"6hour_max\"] = self.data[target].rolling(6).max()\n",
    "            self.data[\"12hour_max\"] = self.data[target].rolling(12).max()\n",
    "            self.data[\"24hour_max\"] = self.data[target].rolling(24).max()\n",
    "            self.data[\"week_max\"] = self.data[target].rolling(24*7).max()\n",
    "            self.data[\"30day_max\"] = self.data[target].rolling(24*30).max()\n",
    "\n",
    "            # Rolling Standard Deviation by Date Cycles\n",
    "            self.data[\"6hour_std\"] = self.data[target].rolling(6).std()\n",
    "            self.data[\"12hour_std\"] = self.data[target].rolling(12).std()\n",
    "            self.data[\"24hour_std\"] = self.data[target].rolling(24).std()\n",
    "            self.data[\"week_std\"] = self.data[target].rolling(24*7).std()\n",
    "            self.data[\"30day_std\"] = self.data[target].rolling(24*30).std()\n",
    "\n",
    "            return self.data\n",
    "\n",
    "    @staticmethod\n",
    "    def wmape(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the Weighted Mean Absolute Percentage Error (WMAPE).\n",
    "\n",
    "        Parameters:\n",
    "        - y_true: The true target values.\n",
    "        - y_pred: The predicted target values.\n",
    "\n",
    "        Returns:\n",
    "        - wmape: The WMAPE score.\n",
    "        \"\"\"\n",
    "        return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "    def wmape_over_df(self, targets):\n",
    "        \"\"\"\n",
    "        Calculate WMAPE scores for multiple target variables.\n",
    "\n",
    "        Parameters:\n",
    "        - targets: The target variables to calculate WMAPE scores for.\n",
    "\n",
    "        Returns:\n",
    "        - wmape_output: List of WMAPE scores and results.\n",
    "        \"\"\"\n",
    "        wmape_output = []\n",
    "\n",
    "        for target in targets:\n",
    "            wmape_stat = self.wmape(self.data[f'next_{target}'], self.data[target])\n",
    "            mean = self.data[target].mean()\n",
    "            std = self.data[target].std()\n",
    "            pred = mean * wmape_stat\n",
    "            result = f'WMAPE Stat - {wmape_stat} | Relative WMAPE Stat - {(pred - mean) / std}'\n",
    "            wmape_output.append({target: {'wmape_stat': wmape_stat, 'result': result}})\n",
    "\n",
    "        self.wmape_output = wmape_output\n",
    "        return wmape_output\n",
    "\n",
    "    def tune_random_forest_hyperparameters(self, X, y):\n",
    "        \"\"\"\n",
    "        Tune the hyperparameters of a Random Forest model using GridSearchCV.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features.\n",
    "        - y: Target variable.\n",
    "\n",
    "        Returns:\n",
    "        - best_params: The best hyperparameters found by GridSearchCV.\n",
    "        - best_score: The best score achieved with the best hyperparameters.\n",
    "        \"\"\"\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "\n",
    "        rf = RandomForestRegressor(random_state=0, n_jobs=6)\n",
    "        grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        self.best_params = grid_search.best_params_\n",
    "        self.best_score = grid_search.best_score_\n",
    "\n",
    "        return self.best_params, self.best_score\n",
    "\n",
    "    def compare_results(self, yval, features, imputer, mdl):\n",
    "        Xval = imputer.transform(self.data[features])\n",
    "        p = mdl.predict(Xval)\n",
    "        return self.wmape(yval, p), p\n",
    "\n",
    "    def fit_model(self, exempt):\n",
    "        features = [feature for feature in self.data.columns if feature not in exempt]\n",
    "        imputer = SimpleImputer()\n",
    "        Xtr = imputer.fit_transform(self.data[features])\n",
    "        ytr = self.data[self.targets]\n",
    "\n",
    "        best_params, best_score = self.tune_random_forest_hyperparameters(Xtr, ytr)\n",
    "\n",
    "        if best_params:\n",
    "            mdl = RandomForestRegressor(n_estimators=best_params.get('n_estimators', 100),\n",
    "                                       max_depth=best_params.get('max_depth', None),\n",
    "                                       min_samples_split=best_params.get('min_samples_split', 2),\n",
    "                                       min_samples_leaf=best_params.get('min_samples_leaf', 1),\n",
    "                                       max_features=best_params.get('max_features', 'auto'),\n",
    "                                       random_state=best_params.get('random_state', 0),\n",
    "                                       n_jobs=best_params.get('n_jobs', 6))\n",
    "        else:\n",
    "            mdl = RandomForestRegressor(n_estimators=100, random_state=0, n_jobs=6)\n",
    "\n",
    "        pred_wmape, pred = self.compare_results(ytr, features, imputer, mdl)\n",
    "\n",
    "        self.model = mdl\n",
    "        self.fit = mdl.fit(Xtr, ytr)\n",
    "        self.wmape = self.wmape_over_df(self.targets)\n",
    "        self.params = best_params\n",
    "        self.score = best_score\n",
    "        self.pred_wmape = pred_wmape\n",
    "        self.pred = pred\n",
    "\n",
    "        return self.output()\n",
    "\n",
    "    def output(self):\n",
    "        \"\"\"\n",
    "        Get the output of the RandomForestModel.\n",
    "\n",
    "        Returns:\n",
    "        - output: A dictionary containing model-related information.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'model': self.model,\n",
    "            'fit': self.fit,\n",
    "            'wmape': self.wmape,\n",
    "            'params': self.params,\n",
    "            'score': self.score,\n",
    "            'pred_wmape': self.pred_wmape,\n",
    "            'pred': self.pred\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "models = []\n",
    "for df in datasets:\n",
    "    models.append(RandomForestModel(df, ['non-violent', 'violent']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
